# Transformer Model Implementation

This repository implements a Transformer model from scratch using PyTorch based on [Umar Jamil's PyTorch Transformer](https://github.com/hkproj/pytorch-transformer/). 

The implementation is supposed to be runnable on a MacBook Air. Modification from original implementation is required.

## Overview

The goal of this project is to provide a clear, line-by-line implementation of the Transformer architecture on a Macbook Air, allowing for a deeper understanding of its components and functionality. 

I also put comments to better illustrate the implementations to help me understand better. These comments are based on verbal descriptions from [Umar Jamil's Youtube video](https://www.youtube.com/watch?v=ISNdQcPhsts),
and my research online. 

## Requirements

Before running the code, please ensure you have the following dependencies installed:

- Python 3.x
- PyTorch 2.0
- Other libraries specified in the `requirements.txt` file


## Setup Instructions

1. Clone the repository:

   ```bash
   git clone https://github.com/trws2/transformer_with_pytorch.git
   cd transformer_with_pytorch
   ```

2. Install required packages:

   ```bash
   pip install -r requirements.txt
   ```

3. Modify the code as necessary for compatibility with your system.

## Usage

Instructions for running the model will be provided here once the implementation is fully functional. 

## Contributions

Feel free to contribute by submitting issues or pull requests. Your feedback and improvements are welcome!

## License

This project is licensed under the MIT License. See the LICENSE file for details.

---

For more details about the Transformer architecture, please refer to the original [Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/).